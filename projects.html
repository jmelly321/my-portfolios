<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - My Portfolio</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Navigation Section -->
    <header>
        <nav>
            <div class="top-bar">
                <p>Data Analyst | Big Data | Business Intelligence</p>
            </div>
            <div class="menu">
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="about.html">About Me</a></li>
                    <li><a href="projects.html">Projects</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </div>
        </nav>
    </header>

    <!-- Projects Page -->
    <section class="projects-page">
        <h1>My Projects</h1>

        <!-- Project 1 -->
        <section id="hadoop-analysis">
            <h2>Employee Data Analysis using Hive</h2>
            <img src="hadoop-logo.png" alt="Hadoop Project">
            <p>In this project, I used Apache Hive to analyze large-scale employee datasets. The insights extracted include:</p>
            <ul>
                <li>Employee performance trends</li>
                <li>Salary distribution across departments</li>
                <li>Turnover rates and hiring patterns</li>
            </ul>
            <a href="your_project_link_here" class="btn">View Project</a>
        </section>

        <!-- Project 2 -->
        <section id="tableau-analysis">
            <h2>Merchandise Sales Analysis Using Tableau</h2>
            <img src="tableau-logo.png" alt="Tableau Project">
            <p>This project involved creating interactive dashboards in Tableau to visualize merchandise sales trends, including:</p>
            <ul>
                <li>Sales performance by region</li>
                <li>Revenue trends over time</li>
                <li>Customer segmentation insights</li>
            </ul>
            <a href="https://public.tableau.com/views/SalesPerState_17423486938320/Dashboard1?:language=en-US&:sid=&:redirect=auth&:display_count=n&:origin=viz_share_link" class="btn">View Project</a>
        </section>

        <!-- Project 3 -->
        <section id="fraud-detection">
            <h2>Fraud Detection Using Random Forest Classifier</h2>
            <img src="fraud.png" alt="Fraud Detection">
            <p>Built a robust fraud detection system to identify fraudulent transactions in financial datasets.Fraud Detection Using Random Forest Classifier As a Machine Learning Engineer in this project, I was tasked with building a robust fraud detection system to identify fraudulent transactions in a large dataset. The company processes millions of financial transactions daily, and detecting fraudulent transactions is crucial to prevent significant financial losses. In this project, I worked on a dataset that contained various transaction details such as amounts, account balances, and transaction types, along with a label indicating whether each transaction was fraudulent or legitimate. The goal was to preprocess the data, build an accurate fraud detection model using a Random Forest Classifier, and address issues like class imbalance to ensure the model's effectiveness. Key Responsibilities and Tasks: Data Preprocessing: oCleaned and preprocessed the dataset by handling missing values, outliers, and inconsistencies. I utilized Pandas to fill in missing values where necessary and applied data transformation techniques to ensure the data was ready for model training. oApplied feature engineering to extract meaningful features from the raw data, ensuring that the model had the best possible inputs for identifying patterns related to fraud. Handling Class Imbalance: oSince the dataset was highly imbalanced (fraudulent transactions were much less frequent than legitimate ones), I employed techniques like class weighting within the Random Forest Classifier to give more importance to fraudulent transactions. oAdditionally, I experimented with SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic samples for the minority class, ensuring the model was not biased toward predicting legitimate transactions and improving detection for fraud. Model Development: oI built a Random Forest Classifier using scikit-learn, leveraging multiple decision trees to enhance prediction accuracy and minimize overfitting. The model was trained to classify transactions as either legitimate or fraudulent based on the features in the dataset. oTuned hyperparameters such as the number of trees (n_estimators), maximum depth of trees (max_depth), and the minimum samples required to split an internal node (min_samples_split) to optimize the model’s performance. Model Evaluation: oEvaluated the model using a variety of metrics, including Precision, Recall, F1 Score, and the Confusion Matrix to measure the model's ability to correctly identify fraudulent transactions while minimizing false positives. oDue to the imbalanced nature of the dataset, I paid particular attention to Precision (the accuracy of positive predictions) and Recall (the ability to correctly identify fraudulent transactions), ensuring a balanced trade-off between these metrics. oPlotted the ROC Curve and calculated the AUC (Area Under the Curve) to assess the model’s performance in distinguishing between legitimate and fraudulent transactions. Model Deployment (if applicable): oCreated a pipeline to integrate the model with real-time transactional data for fraud detection in a production environment. oProvided stakeholders with visual reports and dashboards to track the model's performance in real-time and ensure its effectiveness in identifying fraudulent transactions as new data is processed. Key Tools and Technologies Used: Python Libraries: oscikit-learn: For building and evaluating the Random Forest Classifier, handling hyperparameter tuning, and calculating evaluation metrics. oPandas & NumPy: For data manipulation, cleaning, and feature engineering. oImbalanced-learn: For implementing SMOTE and handling class imbalance. oMatplotlib & Seaborn: For visualizing data distributions, model evaluation metrics, and the ROC curve. Jupyter Notebook: oUsed for developing the project, documenting the analysis, and visualizing results in an interactive environment. Key Achievements: Model Accuracy: Developed a Random Forest Classifier that achieved an F1 Score of X%, demonstrating the model's ability to balance precision and recall effectively in detecting fraudulent transactions. Imbalanced Class Handling: Successfully addressed class imbalance through class weighting and SMOTE, leading to improved fraud detection performance and more reliable predictions on unseen data. Real-time Application Potential: Built a robust model capable of processing millions of transactions, making it suitable for deployment in a production environment where real-time fraud detection is critical. Actionable Insights: Delivered clear, actionable insights for stakeholders on how the model could be integrated into existing systems to detect fraud efficiently and effectively. This project enhanced my understanding of handling imbalanced datasets, applying ensemble methods like Random Forest, and fine-tuning machine learning models for real-world applications, especially in the financial technology domain. </p>
            <a href="///Users/kattykya/Downloads/pythonquiz5datadetectionmodel.pdf" class="btn">View Project</a>
        </section>
        
        <!-- Project 4 -->
        <section id="penetration-testing">
            <h2>Simulated Penetration Testing with Kali Linux</h2>
            <img src="hadooplogo.png" alt="Kali Linux">
            <p>Conducted ethical hacking simulations using Kali Linux tools. Simulated Penetration Testing with Kali Linux: Exploring Ethical Hacking Techniques Objective: As part of my ethical hacking and cybersecurity training, I undertook a simulated penetration testing project using Kali Linux—the premier operating system for penetration testers. The goal of the project was to simulate a real-world cyber attack on a vulnerable system within a controlled, ethical framework. This process helped me explore a variety of ethical hacking techniques, including network scanning, vulnerability assessment, system exploitation, and post-exploitation activities. This portfolio entry outlines the penetration testing methodology I followed, the tools I used, and the results I achieved, offering insights into my hands-on experience with Kali Linux and penetration testing. Tools and Skills During this simulated penetration testing project, I utilized several Kali Linux tools and core skills to complete the penetration testing lifecycle: Kali Linux: A Debian-based Linux distribution used by security professionals for penetration testing and ethical hacking. It comes preloaded with numerous security tools. Nmap: A powerful network scanner that is widely used to discover hosts and services on a computer network. Metasploit: An exploitation framework that allows penetration testers to create and execute exploit code against remote systems. Wireshark: A network protocol analyzer used to capture and inspect packets in real time, helping to identify vulnerabilities in network communications. Burp Suite: A comprehensive suite for web application security testing that helps identify issues like SQL injection, cross-site scripting (XSS), and more. Hydra: A popular tool used to perform brute force attacks on various services like SSH, FTP, HTTP, etc. Aircrack-ng: A suite of tools used for wireless network security testing, focusing on WEP and WPA-PSK encryption cracking. John the Ripper: A tool used to crack password hashes through various methods such as dictionary attacks and brute-forcing. </p>
            <a href="your_project_link_here" class="btn">View Project</a>
        </section>

        <!-- Project 5 -->
        <section id="fruit-grocery-app">
            <h2>Fruit Grocery App Using .NET MAUI</h2>
            <img src="net-maui.jpg" alt="Fruit Grocery App">
            <p>Developed a cross-platform grocery shopping application using .NET MAUI, allowing users to browse and purchase fresh fruits with a seamless experience across Android, iOS, Windows, and macOS. The app integrates Azure SQL Database for secure and scalable data storage, ensuring real-time updates on product availability and pricing. Key features include:

User-friendly interface with an interactive product catalog
Secure authentication and payment processing
Cloud-based data management using Azure SQL
Cross-platform support leveraging .NET MAUI's single codebase
This project showcases my ability to build modern, scalable applications with Microsoft technologies, emphasizing UI/UX design, database management, and cross-platform development.</p>
            <a href="your_project_link_here" class="btn">View Project</a>
        </section>

        <!-- Project 6 -->
        <section id="powerbi-open">
            <h2>Power BI Open Assignment</h2>
            <img src="powerbi.png" alt="Power BI Open Assignment">
            <p>Created interactive dashboards analyzing YouTube subscriber growth trends.The goal of this assignment was to demonstrate my ability to connect to a dataset, analyze it, and creatively visualize insights using Power BI. Specifically, I worked with YouTube subscribers data to explore, clean, and transform the dataset to derive meaningful insights. Through this assignment, I showcased my proficiency in data connection, modeling, and visualization features of Power BI. Conclusion: This Power BI Open Assignment allowed me to demonstrate my ability to effectively analyze and visualize data from an Excel file using Power BI Online. I was able to clean, transform, and model the YouTube subscribers data, and then produce meaningful visualizations that provided key insights into subscriber growth and engagement. Key skills and techniques I applied in this project: Connecting to Excel data in Power BI Online. Cleaning and transforming data to derive actionable insights. Creating visualizations like line charts, scatter plots, and bar charts to represent key data trends. Generating and sharing reports via Power BI Service for collaboration and presentation. By completing this assignment, I further developed my skills in data analysis, visualization, and using Power BI as a powerful business intelligence tool. </p>
            <a href="your_project_link_here" class="btn">View Project</a>
        </section>

        <!-- Project 7 -->
        <section id="powerbi-sales">
            <h2>Power BI Sales Analysis</h2>
            <img src="images.png" alt="Power BI Sales Analysis">
            <p>Analyzed sales data and created dashboards for sales strategy insights. This assignment demonstrates my ability to create meaningful visualizations using Power BI by analyzing sales data. The three tasks provided focus on sales performance, regional sales distribution, and profitability analysis across product categories. I used DAX measures and various visualization types to generate insights that help with decision-making in sales strategy. Conclusion: This assignment allowed me to demonstrate my skills in Power BI, focusing on: Data Modeling: Connecting the Sales, Product, and Region tables to create a robust data model. DAX Measures: Writing DAX measures to calculate key metrics like Total Sales, Sales by Region, and Total Profit. Data Visualization: Creating effective visualizations like Bar Charts and Pie Charts to communicate insights clearly. These visualizations are helpful for decision-making in sales strategy, regional performance analysis, and profitability assessment. This project has strengthened my skills in creating actionable business insights using Power BI.</p>
            <a href="your_project_link_here" class="btn">View Project</a>
        </section>
    </section>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 My Portfolio | Designed for GitHub Pages</p>
    </footer>
</body>
</html>
